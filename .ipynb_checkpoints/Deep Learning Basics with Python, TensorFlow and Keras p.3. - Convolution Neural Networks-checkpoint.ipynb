{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution\n",
    "A floating window will scan the image and using convolution, will \"convert\" the data of the image inside the small window into a value. Than, it will move the window and repeat, until the whole image is convoluted into a smaller array of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22451 samples, validate on 2495 samples\n",
      "Epoch 1/7\n",
      "22451/22451 [==============================] - 434s 19ms/step - loss: 0.6196 - acc: 0.6526 - val_loss: 0.5628 - val_acc: 0.7174\n",
      "Epoch 2/7\n",
      "22451/22451 [==============================] - 405s 18ms/step - loss: 0.5258 - acc: 0.7413 - val_loss: 0.4911 - val_acc: 0.7679\n",
      "Epoch 3/7\n",
      "22451/22451 [==============================] - 414s 18ms/step - loss: 0.4716 - acc: 0.7752 - val_loss: 0.4856 - val_acc: 0.7723\n",
      "Epoch 4/7\n",
      "22451/22451 [==============================] - 412s 18ms/step - loss: 0.4237 - acc: 0.8026 - val_loss: 0.4572 - val_acc: 0.7964\n",
      "Epoch 5/7\n",
      "22451/22451 [==============================] - 563s 25ms/step - loss: 0.3765 - acc: 0.8292 - val_loss: 0.4669 - val_acc: 0.7840\n",
      "Epoch 6/7\n",
      "22451/22451 [==============================] - 553s 25ms/step - loss: 0.3202 - acc: 0.8594 - val_loss: 0.4770 - val_acc: 0.7932\n",
      "Epoch 7/7\n",
      "22451/22451 [==============================] - 343s 15ms/step - loss: 0.2537 - acc: 0.8928 - val_loss: 0.5407 - val_acc: 0.7812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e0b4940f98>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "NAME = \"Cats-vs-dog-cnn-64x2-{}\".format(int(time.time()))  # name the model with unique name\n",
    "\n",
    "# Constants\n",
    "CONVOLUTION_WINDOW = (3, 3)  # define a convolution window\n",
    "LAYER_SIZE = 128  # number of nodes\n",
    "EPOCHS = 7  \n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)  # utilizes 30%\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))  # uses the configuration\n",
    "\n",
    "\n",
    "x = pickle.load(open(\"x.pickle\", \"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\", \"rb\"))\n",
    "\n",
    "# 1st thing we need to do is to normalize the data, for imagry data the easiest way to do that is to divide in the maximum value\n",
    "x = x/255.0\n",
    "\n",
    "model = Sequential()  # create a sequential model\n",
    "\n",
    "model.add(Conv2D(LAYER_SIZE, CONVOLUTION_WINDOW, input_shape=x.shape[1:])) # 64 is the number of nodes\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(LAYER_SIZE, CONVOLUTION_WINDOW, input_shape=x.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(LAYER_SIZE))  # add a Dense layer\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))  # Add output layer with bool value (dog/cat)\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "             optimizer=\"adam\",\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x, y, batch_size=32, epochs=EPOCHS, validation_split=0.1, callbacks=[tensorboard])  # pass 32 at a time, 10% validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dogs_cats_detector.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
